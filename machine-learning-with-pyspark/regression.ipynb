{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Encoding flight origin</h2>\n",
    "The org column in the flights data is a categorical variable giving the airport from which a flight departs.\n",
    "\n",
    "* ORD — O'Hare International Airport (Chicago)\n",
    "* SFO — San Francisco International Airport\n",
    "* JFK — John F Kennedy International Airport (New York)\n",
    "* LGA — La Guardia Airport (New York)\n",
    "* SMF — Sacramento\n",
    "* SJC — San Jose\n",
    "* TUS — Tucson International Airport\n",
    "* OGG — Kahului (Hawaii)\n",
    "\n",
    "Obviously this is only a small subset of airports. Nevertheless, since this is a categorical variable, it needs to be one-hot encoded before it can be used in a regression model.\n",
    "\n",
    "The data are in a variable called flights. You have already used a string indexer to create a column of indexed values corresponding to the strings in org.\n",
    "\n",
    "You might find it useful to revise the slides from the lessons in the Slides panel next to the *IPython Shell*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the one hot encoder class\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "# Create an instance of the one hot encoder\n",
    "onehot = OneHotEncoderEstimator(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot = onehot.fit(flights)\n",
    "flights_onehot = onehot.transform(flights)\n",
    "\n",
    "# Check the results\n",
    "flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Flight duration model: Just distance</h2>\n",
    "In this exercise you'll build a regression model to predict flight duration (the duration column).\n",
    "\n",
    "For the moment you'll keep the model simple, including only the distance of the flight (the km column) as a predictor.\n",
    "\n",
    "The data are in flights. The first few records are displayed in the terminal. These data have also been split into training and testing sets and are available as flights_train and flights_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "predictions = regression.transform(flights_test)\n",
    "predictions.select('duration', 'prediction').show(5, False)\n",
    "\n",
    "# Calculate the RMSE\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\DataCamp\\machine-learning-with-pyspark\\regression.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=0'>1</a>\u001b[0m ingredients \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mBeans\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mSugar\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=7'>8</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSa\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mSalt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=8'>9</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ingredients: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=10'>11</a>\u001b[0m     df[ingredients[i]] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/DataCamp/machine-learning-with-pyspark/regression.ipynb#ch0000018?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39mingredients\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "ingredients = {\n",
    "    'B': 'Beans',\n",
    "    'S': 'Sugar',\n",
    "    'S*': 'Sweetner',\n",
    "    'C': 'Cocoa_Butter',\n",
    "    'V': 'Vanilla',\n",
    "    'L': 'Lecithin',\n",
    "    'Sa': 'Salt'\n",
    "}\n",
    "for i in ingredients: \n",
    "    df[ingredients[i]] = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    for r in row['ingredients'].split(','):\n",
    "        df.loc[idx, ingredients[r]] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Interpreting the coefficients</h2>\n",
    "The linear regression model for flight duration as a function of distance takes the form\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    " — intercept (component of duration which does not depend on distance) and\n",
    " — coefficient (rate at which duration increases as a function of distance; also called the slope).\n",
    "By looking at the coefficients of your model you will be able to infer\n",
    "\n",
    "how much of the average flight duration is actually spent on the ground and\n",
    "what the average speed is during a flight.\n",
    "The linear regression model is available as regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept (average minutes on ground)\n",
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "# Coefficients\n",
    "coefs = regression.coefficients\n",
    "print(coefs)\n",
    "\n",
    "# Average minutes per km\n",
    "minutes_per_km = regression.coefficients[0]\n",
    "print(minutes_per_km)\n",
    "\n",
    "# Average speed in km per hour\n",
    "avg_speed = 60 / minutes_per_km\n",
    "print(avg_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Flight duration model: Adding origin airport</h2>\n",
    "Some airports are busier than others. Some airports are bigger than others too. Flights departing from large or busy airports are likely to spend more time taxiing or waiting for their takeoff slot. So it stands to reason that the duration of a flight might depend not only on the distance being covered but also the airport from which the flight departs.\n",
    "\n",
    "You are going to make the regression model a little more sophisticated by including the departure airport as a predictor.\n",
    "\n",
    "These data have been split into training and testing sets and are available as flights_train and flights_test. The origin airport, stored in the org column, has been indexed into org_idx, which in turn has been one-hot encoded into org_dummy. The first few records are displayed in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting coefficients\n",
    "Remember that origin airport, org, has eight possible values (ORD, SFO, JFK, LGA, SMF, SJC, TUS and OGG) which have been one-hot encoded to seven dummy variables in org_dummy.\n",
    "\n",
    "The values for km and org_dummy have been assembled into features, which has eight columns with sparse representation. Column indices in features are as follows:\n",
    "\n",
    "* 0 — km\n",
    "* 1 — ORD\n",
    "* 2 — SFO\n",
    "* 3 — JFK\n",
    "* 4 — LGA\n",
    "* 5 — SMF\n",
    "* 6 — SJC and\n",
    "* 7 — TUS.\n",
    "Note that OGG does not appear in this list because it is the reference level for the origin airport category.\n",
    "\n",
    "In this exercise you'll be using the intercept and coefficients attributes to interpret the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average speed in km per hour\n",
    "avg_speed_hour = 60/regression.coefficients[0]\n",
    "print(avg_speed_hour)\n",
    "\n",
    "# Average minutes on ground at OGG\n",
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "# Average minutes on ground at JFK\n",
    "avg_ground_jfk = inter + regression.coefficients[3]\n",
    "print(avg_ground_jfk)\n",
    "\n",
    "# Average minutes on ground at LGA\n",
    "avg_ground_lga = inter + regression.coefficients[4]\n",
    "print(avg_ground_lga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bucketing departure time</h2>\n",
    "Time of day data are a challenge with regression models. They are also a great candidate for bucketing.\n",
    "\n",
    "In this lesson you will convert the flight departure times from numeric values between 0 (corresponding to 00:00) and 24 (corresponding to 24:00) to binned values. You'll then take those binned values and one-hot encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer, OneHotEncoderEstimator\n",
    "\n",
    "# Create buckets at 3 hour intervals through the day\n",
    "buckets = Bucketizer(splits=[0, 3, 6, 9, 12, 15, 18, 21, 24], inputCol='depart', outputCol = 'depart_bucket')\n",
    "\n",
    "# Bucket the departure times\n",
    "bucketed = buckets.transform(flights)\n",
    "bucketed.select('depart', 'depart_bucket').show(5)\n",
    "\n",
    "# Create a one-hot encoder\n",
    "onehot = OneHotEncoderEstimator(inputCols = ['depart_bucket'], outputCols = ['depart_dummy'])\n",
    "\n",
    "# One-hot encode the bucketed departure times\n",
    "flights_onehot = onehot.fit(bucketed).transform(bucketed)\n",
    "flights_onehot.select('depart', 'depart_bucket', 'depart_dummy').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Flight duration model: Adding departure time</h2>\n",
    "In the previous exercise the departure time was bucketed and converted to dummy variables. Now you're going to include those dummy variables in a regression model for flight duration.\n",
    "\n",
    "The data are in flights. The km, org_dummy and depart_dummy columns have been assembled into features, where km is index 0, org_dummy runs from index 1 to 7 and depart_dummy from index 8 to 14.\n",
    "\n",
    "The data have been split into training and testing sets and a linear regression model, regression, has been built on the training data. Predictions have been made on the testing data and are available as predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the RMSE on testing data\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 21:00 and 24:00\n",
    "avg_eve_ogg = regression.intercept\n",
    "print(avg_eve_ogg)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 00:00 and 03:00\n",
    "avg_night_ogg = regression.intercept + regression.coefficients[8]\n",
    "print(avg_night_ogg)\n",
    "\n",
    "# Average minutes on ground at JFK for flights departing between 00:00 and 03:00\n",
    "avg_night_jfk = regression.intercept + regression.coefficients[3] + regression.coefficients[8]\n",
    "print(avg_night_jfk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Flight duration model: More features!</h2>\n",
    "Let's add more features to our model. This will not necessarily result in a better model. Adding some features might improve the model. Adding other features might make it worse.\n",
    "\n",
    "More features will always make the model more complicated and difficult to interpret.\n",
    "\n",
    "These are the features you'll include in the next model:\n",
    "\n",
    "* km\n",
    "* org (origin airport, one-hot encoded, 8 levels)\n",
    "* depart (departure time, binned in 3 hour intervals, one-hot encoded, 8 levels)\n",
    "* dow (departure day of week, one-hot encoded, 7 levels) and\n",
    "* mon (departure month, one-hot encoded, 12 levels).\n",
    "\n",
    "These have been assembled into the features column, which is a sparse representation of 32 columns (remember one-hot encoding * produces a number of columns which is one fewer than the number of levels).\n",
    "\n",
    "The data are available as flights, randomly split into flights_train and flights_test.\n",
    "\n",
    "This exercise is based on a small subset of the flights data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Fit linear regression model to training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Make predictions on testing data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Flight duration model: Regularisation!</h2>\n",
    "In the previous exercise you added more predictors to the flight duration model. The model performed well on testing data, but with so many coefficients it was difficult to interpret.\n",
    "\n",
    "In this exercise you'll use Lasso regression (regularized with a L1 penalty) to create a more parsimonious model. Many of the coefficients in the resulting model will be set to zero. This means that only a subset of the predictors actually contribute to the model. Despite the simpler model, it still produces a good RMSE on the testing data.\n",
    "\n",
    "You'll use a specific value for the regularization strength. Later you'll learn how to find the best value using cross validation.\n",
    "\n",
    "The data (same as previous exercise) are available as flights, randomly split into flights_train and flights_test.\n",
    "\n",
    "There are two parameters for this model, λ (regParam) and α (elasticNetParam), where α determines the type of regularization and λ gives the strength of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Fit Lasso model (λ = 1, α = 1) to training data\n",
    "regression = LinearRegression(labelCol='duration', regParam=1, elasticNetParam=1).fit(flights_train)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(regression.transform(flights_test))\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)\n",
    "\n",
    "# Number of zero coefficients\n",
    "zero_coeff = sum([beta == 0 for beta in regression.coefficients])\n",
    "print(\"Number of coefficients equal to 0:\", zero_coeff)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "624741679a3ae5d99cecf49b8df5d516a7a937e6e7328e129d1fa121c8592e26"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
